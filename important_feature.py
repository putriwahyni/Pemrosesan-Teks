# -*- coding: utf-8 -*-
"""PSI_Important Feature.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Tm6CeXnXbovkXwLHzSm3hhfrgv-pyZJV
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import os
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

sns.set(style="whitegrid")

import warnings

warnings.filterwarnings('ignore')

df = pd.read_csv('data_science_job.csv')
df

# print the shape
print('The shape of the dataset : ', df.shape)

df.head()

col_names = ['work_year',	'job_title',	'job_category',	'salary_currency',	'salary',	'salary_in_usd',
             'employee_residence',	'experience_level',	'employment_type',	'work_setting',
             'company_location', 'company_size']

df.columns = col_names

df.columns

df.info()

df.dtypes

df.describe()

df.describe().T

df.describe(include='all')

df.isnull().sum()

def fill_missing_job_category(data, job_title_column='job_title', job_category_column='job_category'):
    """
    Mengisi missing values pada kolom job_category berdasarkan kolom job_title.

    Args:
        data (pd.DataFrame): Dataset dengan kolom job_title dan job_category.
        job_title_column (str, optional): Nama kolom untuk sumber data. Defaults to 'job_title'.
        job_category_column (str, optional): Nama kolom untuk diisi. Defaults to 'job_category'.

    Returns:
        pd.DataFrame: Data dengan kolom job_category yang telah diisi.
    """

    # Mapping dari job title ke job category
    job_title_mapping = {
        'machine learning engineer': 'ML/AI',
        'statistician': 'Analysis',
        'data analyst': 'Analysis',
        'data scientist': 'Data Science',
        'data engineer': 'Engineering',
    }

    # Mengisi missing values pada kolom job_category
    df[job_category_column] = df[job_category_column].fillna(
        df[job_title_column]
        .str.lower()  # Mengubah teks menjadi huruf kecil
        .apply(lambda title: next((v for k, v in job_title_mapping.items() if k in title), 'Other'))
    )

    return df

# Menggunakan fungsi pada dataset
df = fill_missing_job_category(df)

# Mengisi missing values pada kolom 'salary_currency' dengan mode (nilai yang paling sering muncul)
most_common_currency = df['salary_currency'].mode()[0]
df['salary_currency'].fillna(most_common_currency, inplace=True)

# Mengisi missing values pada kolom 'experience_level' dengan 'MI' (Mid-level)
df['experience_level'].fillna('MI', inplace=True)

# Mengisi missing values pada kolom 'company_size' dengan mode (nilai yang paling sering muncul)
most_common_company_size = df['company_size'].mode()[0]
df['company_size'].fillna(most_common_company_size, inplace=True)

# Verifikasi hasil pengisian
print("Missing values setelah pengisian:")
print(df.isnull().sum())

#assert that there are no missing values in the dataframe

assert pd.notnull(df).all().all()

def initial_eda(df):
    if isinstance(df, pd.DataFrame):
        total_na = df.isna().sum().sum()
        print("Dimensions : %d rows, %d columns" % (df.shape[0], df.shape[1]))
        print("Total NA Values : %d " % (total_na))
        print("%38s %10s     %10s %10s" % ("Column Name", "Data Type", "#Distinct", "NA Values"))
        col_name = df.columns
        dtyp = df.dtypes
        uniq = df.nunique()
        na_val = df.isna().sum()
        for i in range(len(df.columns)):
            print("%38s %10s   %10s %10s" % (col_name[i], dtyp[i], uniq[i], na_val[i]))

    else:
        print("Expect a DataFrame but got a %15s" % (type(df)))

initial_eda(df)

categorical = [var for var in df.columns if df[var].dtype=='O']

print('There are {} categorical variables\n'.format(len(categorical)))

print('The categorical variables are :\n\n', categorical)

df[categorical].head()

for var in categorical:

    print(df[var].value_counts())

for var in categorical:
  print(df[var].value_counts()/float(len(df))) # Replace np.float with float

df['job_title'].nunique()

df['job_title'].unique()

df['job_title'].value_counts()

df['job_title'].value_counts()/len(df)

# visualize frequency distribution of income variable
import matplotlib.pyplot as plt
import seaborn as sns

f,ax=plt.subplots(1,2,figsize=(18,8))

# Get the number of unique job titles
num_job_titles = df['job_title'].nunique()

# Create an explode list with the same length as the number of job titles
# Here, we explode the first two slices for demonstration,
# you can adjust the values as needed
explode = [0.1, 0.1] + [0] * (num_job_titles - 2)

ax[0] = df['job_title'].value_counts().plot.pie(explode=explode,autopct='%1.1f%%',ax=ax[0],shadow=True)
ax[0].set_title('job distribution')


#f, ax = plt.subplots(figsize=(6, 8))
ax[1] = sns.countplot(x="job_title", data=df, palette="Set1")
ax[1].set_title("Frequency distribution of job variable")

plt.show()

f, ax = plt.subplots(figsize=(8, 6))
ax = sns.countplot(y="job_title", data=df, palette="Set1")
ax.set_title("Frequency distribution of job variable")
plt.show()

f, ax = plt.subplots(figsize=(10, 8))
ax = sns.countplot(x="job_title", hue="job_category", data=df, palette="Set1")
ax.set_title("Frequency distribution of job variable wrt job category")
plt.show()

numerical = [var for var in df.columns if df[var].dtype!='O']

print('There are {} numerical variables\n'.format(len(numerical)))

print('The numerical variables are :\n\n', numerical)

df[numerical].head()

df[numerical].isnull().sum()

X = df.drop(['job_title'], axis=1)

y = df['job_title']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)

X_train.shape, X_test.shape

categorical = [col for col in X_train.columns if X_train[col].dtypes == 'O']

categorical

numerical = [col for col in X_train.columns if X_train[col].dtypes != 'O']

numerical

X_train[categorical].isnull().mean()

# print categorical variables with missing data

for col in categorical:
    if X_train[col].isnull().mean()>0:
        print(col, (X_train[col].isnull().mean()))

X_train[categorical].isnull().sum()

X_test[categorical].isnull().sum()

# preview categorical variables in X_train

X_train[categorical].head()

# import category encoders
!pip install category_encoders

import category_encoders as ce

# Get the actual column names from X_train
categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()

# Create the OneHotEncoder with the correct column names
encoder = ce.OneHotEncoder(cols=categorical_cols)

# Fit and transform the data
X_train = encoder.fit_transform(X_train)
X_test = encoder.transform(X_test)

X_train.head()

X_train.shape

X_test.head()

X_test.shape

cols = X_train.columns

from sklearn.preprocessing import RobustScaler

scaler = RobustScaler()

X_train = scaler.fit_transform(X_train)

X_test = scaler.transform(X_test)

X_train = pd.DataFrame(X_train, columns=[cols])

X_test = pd.DataFrame(X_test, columns=[cols])

# import Random Forest classifier
from sklearn.ensemble import RandomForestClassifier

# instantiate the classifier
rfc = RandomForestClassifier(random_state=0)

# fit the model
rfc.fit(X_train, y_train)

# Predict the Test set results
y_pred = rfc.predict(X_test)

# Check accuracy score
from sklearn.metrics import accuracy_score

print('Model accuracy score with 10 decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

# instantiate the classifier with n_estimators = 100
rfc_100 = RandomForestClassifier(n_estimators=100, random_state=0)

# fit the model to the training set
rfc_100.fit(X_train, y_train)

# Predict on the test set results
y_pred_100 = rfc_100.predict(X_test)

# Check accuracy score
print('Model accuracy score with 100 decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred_100)))

# create the classifier with n_estimators = 100
clf = RandomForestClassifier(n_estimators=100, random_state=0)


# fit the model to the training set
clf.fit(X_train, y_train)

# view the feature scores
feature_scores = pd.Series(clf.feature_importances_, index=X_train.columns).sort_values(ascending=False)

feature_scores

# prompt: baurtkan digaram berdasarkan score di atas

import matplotlib.pyplot as plt

# Assuming 'feature_scores' is defined as in your previous code
plt.figure(figsize=(12, 6))
feature_scores.plot(kind='bar')
plt.title('Feature Importance Scores')
plt.xlabel('Features')
plt.ylabel('Importance Score')
plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability
plt.tight_layout()
plt.show()